{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiJ_aLtgFcGZ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = '''Chính phủ đề xuất tiếp tục thực hiện chính sách giảm thuế VAT từ 10% còn 8%, trừ một số nhóm hàng hóa, dịch vụ như ngân hàng, bảo hiểm, kinh doanh bất động sản…\n",
        "Bộ trưởng Bộ Tài chính Hồ Đức Phớc chiều 24/5 trình bày Tờ trình về tiếp tục thực hiện chính sách giảm thuế giá trị gia tăng (VAT) 2% theo Nghị quyết số 43/2022/QH15 ngày 11/1/2022. Thời gian đề xuất áp dụng, theo tờ trình, là từ ngày 1/7 đến hết 31/12 năm nay. \n",
        "\n",
        "Theo Bộ trưởng Phớc, thực tế cho thấy, các giải pháp hỗ trợ doanh nghiệp, người dân về thuế, phí và lệ phí nói chung và giảm thuế VAT nói riêng có tác động tích cực và được cộng đồng doanh nghiệp, người dân hưởng ứng, đánh giá cao, qua đó góp phần vào những kết quả tích cực trong phục hồi và phát triển của doanh nghiệp, người dân và nền kinh tế trong thời gian qua.\n",
        "\n",
        "Do vậy, năm 2023 Chính phủ đề xuất tiếp tục thực hiện chính sách giảm thuế VAT 2% quy định tại điểm a khoản 1.1 Điều 3 Nghị quyết số 43/2022/QH15 về chính sách tài khóa, tiền tệ hỗ trợ Chương trình phục hồi và phát triển kinh tế - xã hội.\n",
        "\n",
        "Cụ thể là giảm 2% thuế suất thuế giá trị gia tăng, áp dụng đối với các nhóm hàng hóa, dịch vụ đang áp dụng mức thuế suất 10% (còn 8%), trừ một số nhóm hàng hóa, dịch vụ sau: viễn thông, công nghệ thông tin, hoạt động tài chính, ngân hàng, chứng khoán, bảo hiểm, kinh doanh bất động sản, kim loại, sản phẩm từ kim loại đúc sẵn, sản phẩm khai khoáng (không kể khai thác than), than cốc, dầu mỏ tinh chế, sản phẩm hóa chất, sản phẩm hàng hóa và dịch vụ chịu thuế tiêu thụ đặc biệt. \n",
        "\n",
        "Bộ trưởng Hồ Đức Phớc nhấn mạnh, thực hiện theo phương án này nhằm đảm bảo đúng mục tiêu kích cầu tiêu dùng, phù hợp với bối cảnh kinh tế hiện nay, qua đó thúc đẩy hoạt động sản xuất kinh doanh sớm phục hồi và phát triển để đóng góp trở lại cho ngân sách Nhà nước cũng như nền kinh tế.\n",
        "\n",
        "Với giải pháp giảm thuế VAT cho các đối tượng như đã được thực hiện trong năm 2022 theo Nghị quyết số 43/2022/QH15, nếu áp dụng trong 6 tháng cuối năm nay thì dự kiến số giảm thu ngân sách Nhà nước tương đương khoảng 24.000 tỷ đồng (đối với thu ngân sách Nhà nước năm 2023 thì dự kiến giảm 20.000 tỷ đồng do số thu thuế VAT phải nộp của tháng 12/2023 nộp trong tháng 1/2024).\n",
        "\n",
        "Bộ trưởng Hồ Đức Phớc khẳng định, người dân là đối tượng sẽ được hưởng lợi trực tiếp của chính sách này, việc giảm thuế VAT đối với hàng hóa, dịch vụ chịu thuế suất thuế VAT 10% sẽ góp phần giảm giá bán, từ đó góp phần giảm trực tiếp chi phí của người dân trong việc tiêu dùng hàng hóa, dịch vụ phục vụ đời sống nhân dân.\n",
        "\n",
        "Đối với các doanh nghiệp sản xuất, kinh doanh hàng hóa, cung ứng dịch vụ chịu thuế VAT thuế suất 10% sẽ được hưởng lợi khi chính sách được ban hành. Việc giảm thuế VAT sẽ góp phần làm giảm chi phí sản xuất, hạ giá thành sản phẩm, từ đó giúp doanh nghiệp tăng khả năng phục hồi và mở rộng sản xuất kinh doanh.'''"
      ],
      "metadata": {
        "id": "O2D_cm55LmqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents_parsed = content.lower() #Biến đổi hết thành chữ thường\n",
        "contents_parsed = contents_parsed.replace('\\n', '. ') #Đổi các ký tự xuống dòng thành chấm câu\n",
        "contents_parsed = contents_parsed.strip() #Loại bỏ đi các khoảng trắng thừa"
      ],
      "metadata": {
        "id": "ba6FbukqFkWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGId5OKxNaxj",
        "outputId": "d8f44a43-3e6f-4d27-eb24-7e61699073a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrfkL7_DNmDF",
        "outputId": "3777767b-1779-466a-838f-d5622f7ce4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "sentences = nltk.sent_tokenize(contents_parsed)"
      ],
      "metadata": {
        "id": "c-gEXW-7NAvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "SW5OmRjCMFYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tải tệp tiếng Việt (f)"
      ],
      "metadata": {
        "id": "HlFDFAopfraj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = KeyedVectors.load_word2vec_format(\"/content/vi.vec\")"
      ],
      "metadata": {
        "id": "E0WoUXISFojJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi"
      ],
      "metadata": {
        "id": "-zJoPOJ-OAbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e88225-04f1-46f7-a90a-28905b641dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.1.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = w2v.index_to_key #Danh sách các từ trong từ điển\n",
        "\n",
        "from pyvi import ViTokenizer\n",
        "\n",
        "X = []\n",
        "for sentence in sentences:\n",
        "    sentence_tokenized = ViTokenizer.tokenize(sentence)\n",
        "    words = sentence_tokenized.split(\" \")\n",
        "    sentence_vec = np.zeros((100))\n",
        "    for word in words:\n",
        "        if word in vocab:\n",
        "            sentence_vec += w2v[word]\n",
        "    X.append(sentence_vec)\n"
      ],
      "metadata": {
        "id": "E8IkNnohMHyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 5\n",
        "kmeans = KMeans(n_clusters=n_clusters)\n",
        "kmeans = kmeans.fit(X)"
      ],
      "metadata": {
        "id": "c3hxf1tbP2gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2f8ea0-3890-4fbf-9b9f-4e76651703e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "\n",
        "avg = []\n",
        "for j in range(n_clusters):\n",
        "    idx = np.where(kmeans.labels_ == j)[0]\n",
        "    avg.append(np.mean(idx))\n",
        "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X)\n",
        "ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
        "summary = ' '.join([sentences[closest[idx]] for idx in ordering])"
      ],
      "metadata": {
        "id": "7vZ-fDyTP-38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "pG5nZrbtQCOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "dc778437-2529-4093-9afc-8af35a033405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'. đối với các doanh nghiệp sản xuất, kinh doanh hàng hóa, cung ứng dịch vụ chịu thuế vat thuế suất 10% sẽ được hưởng lợi khi chính sách được ban hành. cụ thể là giảm 2% thuế suất thuế giá trị gia tăng, áp dụng đối với các nhóm hàng hóa, dịch vụ đang áp dụng mức thuế suất 10% (còn 8%), trừ một số nhóm hàng hóa, dịch vụ sau: viễn thông, công nghệ thông tin, hoạt động tài chính, ngân hàng, chứng khoán, bảo hiểm, kinh doanh bất động sản, kim loại, sản phẩm từ kim loại đúc sẵn, sản phẩm khai khoáng (không kể khai thác than), than cốc, dầu mỏ tinh chế, sản phẩm hóa chất, sản phẩm hàng hóa và dịch vụ chịu thuế tiêu thụ đặc biệt. bộ trưởng hồ đức phớc nhấn mạnh, thực hiện theo phương án này nhằm đảm bảo đúng mục tiêu kích cầu tiêu dùng, phù hợp với bối cảnh kinh tế hiện nay, qua đó thúc đẩy hoạt động sản xuất kinh doanh sớm phục hồi và phát triển để đóng góp trở lại cho ngân sách nhà nước cũng như nền kinh tế.. . với giải pháp giảm thuế vat cho các đối tượng như đã được thực hiện trong năm 2022 theo nghị quyết số 43/2022/qh15, nếu áp dụng trong 6 tháng cuối năm nay thì dự kiến số giảm thu ngân sách nhà nước tương đương khoảng 24.000 tỷ đồng (đối với thu ngân sách nhà nước năm 2023 thì dự kiến giảm 20.000 tỷ đồng do số thu thuế vat phải nộp của tháng 12/2023 nộp trong tháng 1/2024).. .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sử dụng LSTM"
      ],
      "metadata": {
        "id": "3IJHcBcrSzgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0].shape)"
      ],
      "metadata": {
        "id": "V7a6QsLGk5Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41120a57-1d10-48de-ccb8-9b2537748b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# X là ma trận biểu diễn các câu đã chuẩn hóa, có kích thước (số câu, độ dài câu, 1)\n",
        "\n",
        "# Chuẩn bị dữ liệu đầu vào\n",
        "X = np.array(X)  # Biểu diễn câu\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # Reshape đầu vào thành (số lượng mẫu, độ dài câu, 1) để phù hợp với input của mô hình\n",
        "\n",
        "# Xây dựng mô hình LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))  # Input shape là (độ dài câu, 1)\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(X.shape[2]))  # Output shape là (1,)\n",
        "\n",
        "\n",
        "# Compile và huấn luyện mô hình\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(X, X, epochs=60, batch_size=32)  # Input và output đều là X\n",
        "\n",
        "# Sử dụng mô hình để chọn câu trong bài văn\n",
        "selected_sentences = []\n",
        "selected_indices = set()  # Lưu các chỉ số của câu đã được chọn\n",
        "for i in range(X.shape[0]):\n",
        "    sentence_vec = np.reshape(X[i], (1, X.shape[1], X.shape[2]))  # Reshape câu thành (1, độ dài câu, 1) để phù hợp với input của mô hình\n",
        "    sentence_representation = model.predict(sentence_vec)[0]\n",
        "    # Thực hiện các bước lựa chọn câu dựa trên biểu diễn câu, ví dụ như sử dụng ngưỡng, độ tương đồng, hay các tiêu chí khác\n",
        "    \n",
        "    # Kiểm tra xem câu đã được chọn trước đó chưa và không trùng lặp với các câu đã chọn trước\n",
        "    if i not in selected_indices and sentence not in selected_sentences:\n",
        "        # Nếu câu được chọn, thêm vào danh sách các câu đã chọn và cập nhật danh sách chỉ số\n",
        "        selected_sentences.append(sentence)\n",
        "        selected_indices.add(i)\n",
        "\n",
        "# Tạo tóm tắt từ các câu đã chọn\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "9tkMyUDSn3Wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be25d2c-d7ef-49c7-9b2e-85a6997775f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "1/1 [==============================] - 4s 4s/step - loss: 20.2965\n",
            "Epoch 2/60\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 20.2575\n",
            "Epoch 3/60\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 20.2178\n",
            "Epoch 4/60\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 20.1684\n",
            "Epoch 5/60\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 20.1104\n",
            "Epoch 6/60\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 20.0543\n",
            "Epoch 7/60\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 20.0311\n",
            "Epoch 8/60\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 20.0744\n",
            "Epoch 9/60\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 20.0782\n",
            "Epoch 10/60\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 20.0495\n",
            "Epoch 11/60\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 20.0304\n",
            "Epoch 12/60\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 20.0297\n",
            "Epoch 13/60\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 20.0378\n",
            "Epoch 14/60\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 20.0446\n",
            "Epoch 15/60\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 20.0465\n",
            "Epoch 16/60\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 20.0434\n",
            "Epoch 17/60\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 20.0373\n",
            "Epoch 18/60\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 20.0304\n",
            "Epoch 19/60\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 20.0251\n",
            "Epoch 20/60\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 20.0238\n",
            "Epoch 21/60\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 20.0261\n",
            "Epoch 22/60\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 20.0284\n",
            "Epoch 23/60\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 20.0273\n",
            "Epoch 24/60\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 20.0229\n",
            "Epoch 25/60\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 20.0188\n",
            "Epoch 26/60\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 20.0173\n",
            "Epoch 27/60\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 20.0180\n",
            "Epoch 28/60\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 20.0189\n",
            "Epoch 29/60\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 20.0182\n",
            "Epoch 30/60\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 20.0157\n",
            "Epoch 31/60\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 20.0126\n",
            "Epoch 32/60\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 20.0106\n",
            "Epoch 33/60\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 20.0102\n",
            "Epoch 34/60\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 20.0105\n",
            "Epoch 35/60\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 20.0088\n",
            "Epoch 36/60\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 20.0052\n",
            "Epoch 37/60\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 20.0038\n",
            "Epoch 38/60\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 20.0048\n",
            "Epoch 39/60\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 20.0042\n",
            "Epoch 40/60\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 20.0029\n",
            "Epoch 41/60\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 20.0042\n",
            "Epoch 42/60\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 20.0017\n",
            "Epoch 43/60\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 20.0018\n",
            "Epoch 44/60\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 20.0001\n",
            "Epoch 45/60\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 19.9988\n",
            "Epoch 46/60\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 19.9990\n",
            "Epoch 47/60\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 19.9978\n",
            "Epoch 48/60\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 19.9971\n",
            "Epoch 49/60\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 19.9971\n",
            "Epoch 50/60\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 19.9961\n",
            "Epoch 51/60\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 19.9947\n",
            "Epoch 52/60\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 19.9944\n",
            "Epoch 53/60\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 19.9928\n",
            "Epoch 54/60\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 19.9928\n",
            "Epoch 55/60\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 19.9921\n",
            "Epoch 56/60\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 19.9931\n",
            "Epoch 57/60\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 19.9932\n",
            "Epoch 58/60\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 19.9915\n",
            "Epoch 59/60\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 19.9935\n",
            "Epoch 60/60\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 19.9914\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Summary: việc giảm thuế vat sẽ góp phần làm giảm chi phí sản xuất, hạ giá thành sản phẩm, từ đó giúp doanh nghiệp tăng khả năng phục hồi và mở rộng sản xuất kinh doanh.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# X là ma trận biểu diễn các câu đã chuẩn hóa, có kích thước (số câu, độ dài câu, 1)\n",
        "\n",
        "# Chuẩn bị dữ liệu đầu vào\n",
        "X = np.array(X)  # Biểu diễn câu\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # Reshape đầu vào thành (số lượng mẫu, độ dài câu, 1) để phù hợp với input của mô hình\n",
        "\n",
        "# Xây dựng mô hình LSTM với lớp ẩn và dropout\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))  # Input shape là (độ dài câu, 1)\n",
        "                                                                           #return_sequences=True để giữ lại các đầu ra của tất cả các thời điểm\n",
        "model.add(Dropout(0.2))  # Sử dụng dropout để giảm overfitting\n",
        "model.add(LSTM(128))  # Lớp ẩn thứ 2 không cần chỉ định input shape vì nó tự động lấy input từ lớp trước đó\n",
        "model.add(Dropout(0.2))  # Sử dụng dropout để giảm overfitting\n",
        "model.add(Dense(X.shape[2]))  # Output shape là (1,)\n",
        "\n",
        "# Compile và huấn luyện mô hình\n",
        "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, X, epochs=100, batch_size=32)  # Input và output đều là X\n",
        "model.summary()\n",
        "model.save('Autoencoder Model.h5')\n",
        "# Sử dụng mô hình để chọn câu trong bài văn\n",
        "selected_sentences = []\n",
        "selected_indices = set()  # Lưu các chỉ số của câu đã được chọn\n",
        "for i in range(X.shape[0]):\n",
        "    sentence_vec = np.reshape(X[i], (1, X.shape[1], X.shape[2]))  # Reshape câu thành (1, độ dài câu, 1) để phù hợp với input của mô hình\n",
        "    sentence_representation = model.predict(sentence_vec)[0]\n",
        "    # Thực hiện các bước lựa chọn câu dựa trên biểu diễn câu, ví dụ như sử dụng ngưỡng, độ tương đồng, hay các tiêu chí khác\n",
        "    \n",
        "    # Kiểm tra xem câu đã được chọn trước đó chưa và không trùng lặp với các câu đã chọn trước\n",
        "    if i not in selected_indices and sentence not in selected_sentences:\n",
        "        # Nếu câu được chọn, thêm vào danh sách các câu đã chọn và cập nhật danh sách chỉ số\n",
        "        selected_sentences.append(sentence)\n",
        "        selected_indices.add(i)\n",
        "\n",
        "# Tạo tóm tắt từ các câu đã chọn\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "1MukLKUAAAgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6402a1-5b02-403a-8fd2-43e90e258754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 20.1802 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 20.0657 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 20.0414 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 20.0643 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 20.0701 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 20.0284 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 20.0123 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 20.0214 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 20.0294 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 20.0329 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 20.0258 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 20.0261 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 20.0202 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 20.0151 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 20.0144 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 20.0150 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 20.0191 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 20.0091 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 20.0072 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 20.0122 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 20.0060 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 20.0016 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 20.0028 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 20.0034 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 20.0082 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 20.0048 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 20.0002 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 20.0043 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 20.0042 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 20.0001 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 20.0016 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 19.9995 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 19.9977 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 20.0009 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 20.0027 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 19.9998 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 20.0008 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 19.9969 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 20.0017 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 19.9999 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 19.9971 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 19.9954 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 19.9970 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 19.9940 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 20.0004 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 19.9971 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 19.9975 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 19.9947 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 20.0046 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 20.0011 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 19.9961 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 19.9938 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 19.9984 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 19.9960 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 19.9958 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 19.9915 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 19.9933 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 19.9911 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 19.9949 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 19.9926 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 19.9924 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 19.9917 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 19.9923 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 19.9956 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 19.9914 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 19.9901 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 19.9898 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 19.9943 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 19.9925 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 19.9917 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 19.9948 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 19.9919 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 19.9911 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 19.9919 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 19.9940 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 19.9952 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 19.9924 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 19.9928 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 19.9910 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 19.9900 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 19.9900 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 19.9894 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 19.9939 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 19.9921 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 19.9937 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 19.9916 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 19.9914 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 19.9961 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 19.9898 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 19.9931 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 19.9900 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 19.9907 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 19.9903 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 19.9926 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 19.9901 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 19.9976 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 19.9899 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 19.9964 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 19.9901 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 19.9916 - accuracy: 0.0000e+00\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 100, 128)          66560     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 128)          0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198,273\n",
            "Trainable params: 198,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 1s 938ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Summary: việc giảm thuế vat sẽ góp phần làm giảm chi phí sản xuất, hạ giá thành sản phẩm, từ đó giúp doanh nghiệp tăng khả năng phục hồi và mở rộng sản xuất kinh doanh.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình 1 lần\n"
      ],
      "metadata": {
        "id": "RLtRbQ34pms-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, RepeatVector, concatenate, TimeDistributed, Dense\n"
      ],
      "metadata": {
        "id": "IQPea7A4sTMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "import numpy as np\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "vocab_size = 150\n",
        "src_txt_length = 100\n",
        "sum_txt_length = 200\n",
        "\n",
        "# Padding the input sequences\n",
        "X = pad_sequences(X, maxlen=src_txt_length, padding='post', truncating='post')\n",
        "\n",
        "# Converting the input sequences to one-hot encoded format\n",
        "X = to_categorical(X, num_classes=vocab_size)\n",
        "\n",
        "# Encoder input model\n",
        "inputs = Input(shape=(src_txt_length, vocab_size))\n",
        "encoder1 = LSTM(128)(inputs)\n",
        "encoder2 = RepeatVector(sum_txt_length)(encoder1)\n",
        "\n",
        "# Decoder output model\n",
        "decoder1 = LSTM(128, return_sequences=True)(encoder2)\n",
        "outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Use the model to select sentences in the text\n",
        "selected_sentences = []\n",
        "selected_indices = set()  # Store the indices of the selected sentences\n",
        "for i in range(X.shape[0]):\n",
        "    sentence_vec = np.reshape(X[i], (1, src_txt_length, vocab_size))  # Reshape the sentence to match the model's input\n",
        "    sentence_representation = model.predict(sentence_vec)[0]\n",
        "    # Perform sentence selection based on the sentence representation, e.g., using a threshold, similarity, or other criteria\n",
        "\n",
        "    # Check if the sentence has been selected before and avoid duplicates\n",
        "    if i not in selected_indices and sentence not in selected_sentences:\n",
        "        # If the sentence is selected, add it to the list of selected sentences and update the index list\n",
        "        selected_sentences.append(sentence)\n",
        "        selected_indices.add(i)\n",
        "\n",
        "# Create a summary from the selected sentences\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "94-IxckJprRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b335d3-223a-484a-e2e5-17dfec79d107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 857ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Summary: việc giảm thuế vat sẽ góp phần làm giảm chi phí sản xuất, hạ giá thành sản phẩm, từ đó giúp doanh nghiệp tăng khả năng phục hồi và mở rộng sản xuất kinh doanh.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô Hình Đệ Quy A"
      ],
      "metadata": {
        "id": "wDScNTPXsXs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, RepeatVector, concatenate, Dense\n",
        "import numpy as np\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "vocab_size = 100\n",
        "src_txt_length = 30\n",
        "sum_txt_length = 100\n",
        "\n",
        "# Padding the input sequences\n",
        "X = pad_sequences(X, maxlen=src_txt_length, padding='post', truncating='post')\n",
        "\n",
        "# Converting the input sequences to one-hot encoded format\n",
        "X = to_categorical(X, num_classes=vocab_size)\n",
        "\n",
        "# Source text input model\n",
        "inputs1 = Input(shape=(src_txt_length,))\n",
        "am1 = Embedding(vocab_size, 128)(inputs1)\n",
        "am2 = LSTM(128)(am1)\n",
        "\n",
        "# Decoder output model\n",
        "outputs = Dense(vocab_size, activation='softmax')(am2)\n",
        "\n",
        "# Tie it together [source text] [word]\n",
        "model = Model(inputs=inputs1, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Use the model to select sentences in the text\n",
        "selected_sentences = []\n",
        "selected_indices = set()  # Store the indices of the selected sentences\n",
        "for i in range(X.shape[0]):\n",
        "    sentence_vec = np.reshape(X[i], (1, src_txt_length, vocab_size))\n",
        "    sentence_representation = model.predict(sentence_vec)[0]\n",
        "    # Perform sentence selection based on the sentence representation, e.g., using a threshold, similarity, or other criteria\n",
        "\n",
        "    # Check if the sentence has been selected before and avoid duplicates\n",
        "    if i not in selected_indices and sentence not in selected_sentences:\n",
        "        # If the sentence is selected, add it to the list of selected sentences and update the index list\n",
        "        selected_sentences.append(sentence)\n",
        "        selected_indices.add(i)\n",
        "\n",
        "# Create a summary from the selected sentences\n",
        "summary = \" \".join(selected_sentences)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "Gnb_RnGpsXHJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "6998fa6e-8f91-432c-b87d-2b89a93b48cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4570ab1c6d1b>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mselected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Store the indices of the selected sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msentence_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_txt_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0msentence_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Perform sentence selection based on the sentence representation, e.g., using a threshold, similarity, or other criteria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 450000 into shape (1,30,100)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô Hình Đệ Quy B"
      ],
      "metadata": {
        "id": "BzH_8j-Ts6rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 150\n",
        "src_txt_length = 100\n",
        "sum_txt_length = 200\n",
        "# article input model\n",
        "inputs1 = Input(shape=(src_txt_length,))\n",
        "article1 = Embedding(vocab_size, 128)(inputs1)\n",
        "article2 = LSTM(128)(article1)\n",
        "article3 = RepeatVector(sum_txt_length)(article2)\n",
        "# summary input model\n",
        "inputs2 = Input(shape=(sum_txt_length,))\n",
        "summ1 = Embedding(vocab_size, 128)(inputs2)\n",
        "# decoder model\n",
        "decoder1 = concatenate([article3, summ1])\n",
        "decoder2 = LSTM(128)(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "# tie it together [article, summary] [word]\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "J33RMudktFrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}